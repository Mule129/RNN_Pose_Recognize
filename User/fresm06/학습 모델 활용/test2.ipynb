{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cProfile import label\n",
    "#from tensorflow.python.keras.utils import to_categorical\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import mediapipe as mp\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import LSTM, Dense\n",
    "from tensorflow.python.keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'to_categorical' from 'tensorflow.python.keras.utils' (c:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dohcv\\Desktop\\just for test\\test2.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m to_categorical\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'to_categorical' from 'tensorflow.python.keras.utils' (c:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dohcv\\Desktop\\just for test\\test2.ipynb 셀 2\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#W1sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m DATA_PATH \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39mdataset1\u001b[39m\u001b[39m'\u001b[39m) \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#W1sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# 사용할 액션을 지정\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#W1sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m actions \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m'\u001b[39m\u001b[39mfront\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#W1sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m mp_pose \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mpose \u001b[39m# 홀리스틱 모델을 불러오고\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#W1sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m mp_drawing \u001b[39m=\u001b[39m mp\u001b[39m.\u001b[39msolutions\u001b[39m.\u001b[39mdrawing_utils \u001b[39m# 영상 켰을때 보이는 선이랑 점을 그리기 위한 드로잉 유틸 불러오기\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# 각 액션마다 30개의 영상을 저장할 예정을 밝힘\n",
    "no_sequences = 30\n",
    "\n",
    "#각 영상은30프레임 사용\n",
    "sequence_length = 30\n",
    "\n",
    "# 데이터를 저장할 파일 경로 안내\n",
    "DATA_PATH = os.path.join('dataset1') \n",
    "\n",
    "# 사용할 액션을 지정\n",
    "actions = np.array(['front'])\n",
    "\n",
    "mp_pose = mp.solutions.pose # 홀리스틱 모델을 불러오고\n",
    "mp_drawing = mp.solutions.drawing_utils # 영상 켰을때 보이는 선이랑 점을 그리기 위한 드로잉 유틸 불러오기\n",
    "\n",
    "#로그라는 폴더 만들기 아마 뉴런 제작 예정 폴더 일듯\n",
    "log_dir = os.path.join('Logs')\n",
    "tb_callback = TensorBoard(log_dir=log_dir)\n",
    "\n",
    "def mediapipe_detection(image, model):\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # BRG형식의 이미지를 RGB로 변환\n",
    "    image.flags.writeable = False                  # 더이상 이미지는 쓰기가 안됨\n",
    "    results = model.process(image)                 # Make prediction?\n",
    "    image.flags.writeable = True                   # 이미지 쓰기가 가능해짐\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR) # RGB형식의 이미지를 RGB로 변환\n",
    "    return image, results\n",
    "\n",
    "def draw_landmarks(image, results):\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30, 30, 132)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "def draw_styled_landmarks(image, results):\n",
    "    #포즈 연결 선 그리기\n",
    "    mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                             mp_drawing.DrawingSpec(color=(250,250,250), thickness=2, circle_radius=4), \n",
    "                             mp_drawing.DrawingSpec(color=(250,250,250), thickness=2, circle_radius=2)\n",
    "                             ) \n",
    "#여기는 x, y, z 그리고 보이는 시점의 값\n",
    "def extract_keypoints(results):\n",
    "    pose = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten() if results.pose_landmarks else np.zeros(33*4)\n",
    "    return np.concatenate([pose])\n",
    "\n",
    "label_map = {label:num for num, label in enumerate(actions)}\n",
    "#시퀀스와 라벨이 비어있는 리스트 생성\n",
    "sequences, labels = [], []\n",
    "#액션 안에 액션스 를 저장\n",
    "for action in actions:\n",
    "    for sequence in range(no_sequences):\n",
    "        window = []\n",
    "        #append 는 리스트 안에 변수 추가하는 명령어\n",
    "        for frame_num in range(sequence_length):\n",
    "            res = np.load(os.path.join(DATA_PATH, action, str(sequence), \"{}.npy\".format(frame_num)))\n",
    "\n",
    "            window.append(res)\n",
    "        sequences.append(window)\n",
    "        labels.append(label_map[action])\n",
    "#LSTM활용해서 렐루활성 함수를 사용해 RNN으로 예측 한다.\n",
    "#위에서 프린트해본 총 리스트의 모양을 입력함으로써 이를 경로 설정해준뒤, 이 학습 데이터를 저장\n",
    "x = np.array(sequences)\n",
    "print(x.shape)\n",
    "print(np.array(labels).shape)\n",
    "y = to_categorical(labels).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 132)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sequences).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 132)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(30,132)))\n",
    "model.add(LSTM(128, return_sequences=True, activation='relu'))\n",
    "model.add(LSTM(64, return_sequences=False, activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(actions.shape[0], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'front'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = [.7, 0.2, 0.1]\n",
    "actions[np.argmax(res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 6s 6s/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0000e+00 - categorical_accuracy: 1.0000\n",
      "Epoch 54/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\dohcv\\Desktop\\just for test\\test2.ipynb 셀 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/dohcv/Desktop/just%20for%20test/test2.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m2000\u001b[39;49m, callbacks\u001b[39m=\u001b[39;49m[tb_callback])\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1189\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\n\u001b[0;32m   1183\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1184\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   1185\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[0;32m   1186\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[0;32m   1187\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[0;32m   1188\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1189\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[0;32m   1190\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[0;32m   1191\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateless_fn(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[0;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[0;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[0;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[0;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[0;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[0;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[0;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[0;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mc:\\Users\\dohcv\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[0;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=2000, callbacks=[tb_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ee1f2ca25956bed3bf5fc86ab54aba736ea29e2ff2e58464c66967945b5c7a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
